import time
import json
import re
import sys
import argparse
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.edge.service import Service as EdgeService
from webdriver_manager.microsoft import EdgeChromiumDriverManager

def load_cookies_from_file(filename):
    cookies = []
    with open(filename, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line.startswith("#") or not line:
                continue
            parts = line.split("\t")
            if len(parts) != 7:
                continue
            domain, flag, path, secure, expiration, name, value = parts
            cookie = {
                "domain": domain,
                "name": name,
                "value": value,
                "path": path,
                "secure": secure.upper() == "TRUE",
                "expiry": int(expiration) if expiration.isdigit() else None,
            }
            cookies.append(cookie)
    return cookies

def parse_time(text, today_str):
    today = datetime.strptime(today_str, "%Y-%m-%d")

    def parse_hour(period, hour, minute):
        hour, minute = int(hour), int(minute)
        if period in ("ä¸‹åˆ", "æ™šä¸Š") and hour != 12:
            hour += 12
        elif period == "å‡Œæ™¨":
            hour = 0 if hour == 12 else hour
        elif period == "ä¸Šåˆ" and hour == 12:
            hour = 0
        return hour, minute

    # 1. 2023å¹´3æœˆ5æ—¥ ä¸Šåˆ10:20
    m = re.match(r"(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥\s+(å‡Œæ™¨|ä¸Šåˆ|ä¸‹åˆ|æ™šä¸Š)(\d{1,2}):(\d{2})", text)
    if m:
        year, month, day, period, hour, minute = m.groups()
        hour, minute = parse_hour(period, hour, minute)
        dt = datetime(int(year), int(month), int(day), hour, minute)
        return dt.isoformat() + "Z"

    # 2. 3æœˆ5æ—¥ ä¸Šåˆ10:20
    m = re.match(r"(\d{1,2})æœˆ(\d{1,2})æ—¥\s+(å‡Œæ™¨|ä¸Šåˆ|ä¸‹åˆ|æ™šä¸Š)(\d{1,2}):(\d{2})", text)
    if m:
        month, day, period, hour, minute = m.groups()
        hour, minute = parse_hour(period, hour, minute)
        dt = datetime(today.year, int(month), int(day), hour, minute)
        if dt > today:
            dt = dt.replace(year=today.year - 1)
        return dt.isoformat() + "Z"

    # 3. ä»Šå¤©/æ˜¨å¤© ä¸Šåˆ10:20
    if text.startswith("ä»Šå¤© ") or text.startswith("æ˜¨å¤© "):
        day_part, time_part = text.split()
        base_date = today if day_part == "ä»Šå¤©" else today - timedelta(days=1)
        m = re.match(r"(å‡Œæ™¨|ä¸Šåˆ|ä¸‹åˆ|æ™šä¸Š)(\d{1,2}):(\d{2})", time_part)
        if not m:
            return None
        period, hour, minute = m.groups()
        hour, minute = parse_hour(period, hour, minute)
        return base_date.replace(hour=hour, minute=minute).isoformat() + "Z"

    return None

def scroll_to_bottom(driver, pause=2, max_idle=3):
    last_height = driver.execute_script("return document.documentElement.scrollHeight")
    idle_rounds = 0
    while idle_rounds < max_idle:
        driver.execute_script("window.scrollTo(0, document.documentElement.scrollHeight);")
        time.sleep(pause)
        new_height = driver.execute_script("return document.documentElement.scrollHeight")
        if new_height == last_height:
            idle_rounds += 1
        else:
            idle_rounds = 0
            last_height = new_height

def scroll_one_step_to_bottom(driver, pause=2):
    last_height = driver.execute_script("return document.documentElement.scrollHeight")
    driver.execute_script("window.scrollTo(0, document.documentElement.scrollHeight);")
    time.sleep(pause)
    new_height = driver.execute_script("return document.documentElement.scrollHeight")
    return new_height > last_height

def date_to_timestamp(date_str):
    dt = datetime.strptime(date_str, "%Y/%m/%d")
    end_of_day = dt.replace(hour=23, minute=59, second=59, microsecond=999000)
    return int(end_of_day.timestamp() * 1e6)

def get_youtube_history_url(date_str=None):
    base_url = "https://myactivity.google.com/product/youtube?restrict=youtube"
    if date_str:
        max_timestamp = date_to_timestamp(date_str)
        return f"{base_url}&max={max_timestamp}"
    return base_url

def main(start_date=None, end_date=None, output_file="youtube_watch_history_stream.json"):
    cookies = load_cookies_from_file("myactivity.google.com_cookies.txt")
    today_str = datetime.today().strftime("%Y-%m-%d")
    end_dt = None
    if end_date:
        end_dt = datetime.strptime(end_date, "%Y/%m/%d")

    options = webdriver.EdgeOptions()
    options.add_argument("--start-maximized")
    driver = webdriver.Edge(service=EdgeService(EdgeChromiumDriverManager().install()), options=options)

    # start_date å°æ‡‰ max= åƒæ•¸ï¼Œend_date ç‚ºçµæŸæ¢ä»¶
    url = get_youtube_history_url(start_date)
    driver.get(url)
    for cookie in cookies:
        try:
            driver.add_cookie(cookie)
        except:
            pass
    driver.refresh()
    time.sleep(5)
    input("âœ… æ‰‹å‹•ç¢ºèªå·²ç™»å…¥ä¸¦é¡¯ç¤ºæ´»å‹•å¾Œï¼ŒæŒ‰ Enter ç¹¼çºŒ...")

    seen_urls = set()
    seen_logs = set()
    results = []

    MAX_SCROLL_ROUNDS = float('inf')
    EMPTY_ROUND_THRESHOLD = 3
    rounds = 0
    empty_rounds = 0
    last_header = None

    while rounds < MAX_SCROLL_ROUNDS:
        print(f"\n[SCROLL] ç¬¬ {rounds + 1} æ¬¡æ²å‹• ğŸ”½")
        scroll_one_step_to_bottom(driver, pause=3)

        activities = driver.find_elements(By.CSS_SELECTOR, "div[role='listitem'], div.CW0isc")
        print(f"[INFO] æ´»å‹•+æ—¥æœŸå€å¡Šæ•¸é‡ï¼š{len(activities)}")
        new_found = 0

        for act in activities:
            try:
                headers = act.find_elements(By.CSS_SELECTOR, "div.MCZgpb > h2.rp10kf")
                if headers:
                    latest = headers[-1].text.strip()
                    if latest in seen_urls:
                        continue
                    seen_urls.add(latest)
                    if latest and latest != last_header:
                        last_header = latest
                        print(f"[ğŸ“… æ—¥æœŸæ›´æ–°] ç¾åœ¨ä½¿ç”¨ï¼š{last_header}")
                
                title_elems = act.find_elements(By.CSS_SELECTOR, "div.QTGV3c a.l8sGWb")
                if not title_elems:
                    continue  # æ²’æœ‰é€£çµçš„æ´»å‹•ç•¥é
                title_elem = title_elems[0]
                title = title_elem.text.strip()
                title_url = title_elem.get_attribute("href")

                # æª¢æŸ¥æ˜¯å¦ç‚ºæœå°‹æ´»å‹•
                if title_url and "search_query=" in title_url:
                    if title_url in seen_urls:
                        continue
                    seen_urls.add(title_url)
                    print(f"[LOG] æœå°‹æ´»å‹•åµæ¸¬åˆ°ï¼š{title}", flush=True)
                    continue  # ç›®å‰ä¸è™•ç†æœå°‹æ´»å‹•

                # æª¢æŸ¥æ˜¯å¦ç‚ºå·²æŸ¥çœ‹æ´»å‹•
                qtgv3c_text = act.find_element(By.CSS_SELECTOR, "div.QTGV3c").text.strip()
                if qtgv3c_text.startswith("å·²æŸ¥çœ‹ã€Œ"):
                    if qtgv3c_text in seen_logs:
                        continue
                    seen_logs.add(qtgv3c_text)
                    print(f"[LOG] å·²æŸ¥çœ‹æ´»å‹•åµæ¸¬åˆ°ï¼š{qtgv3c_text}", flush=True)
                    continue  # ç›®å‰ä¸è™•ç†å·²æŸ¥çœ‹æ´»å‹•

                if title_url in seen_urls or not title:
                    continue
                seen_urls.add(title_url)

                time_text = act.find_element(By.CSS_SELECTOR, "div.H3Q9vf.XTnvW").text
                time_label = time_text.split("â€¢")[0].strip()

                if not last_header:
                    continue  # skip if no header yet

                full_time = f"{last_header} {time_label}"
                time_iso = parse_time(full_time, today_str)
                if not time_iso:
                    continue
                # æ–°å¢çµæŸæ¢ä»¶ï¼šè‹¥ time_iso < end_dateï¼Œå‰‡çµ‚æ­¢çˆ¬èŸ²
                if end_dt:
                    try:
                        activity_dt = datetime.fromisoformat(time_iso.replace("Z", ""))
                        if activity_dt < end_dt:
                            print(f"[STOP] å·²é”çµæŸæ—¥æœŸ {end_date}ï¼Œçµ‚æ­¢çˆ¬èŸ²")
                            driver.quit()
                            print(f"\nâœ… å…±å„²å­˜ {len(results)} ç­†æ´»å‹•è‡³ {output_file}")
                            return
                    except Exception as e:
                        print(f"[WARN] æ—¥æœŸè§£æå¤±æ•—: {e}")

                subtitles = []
                try:
                    ch_elem = act.find_element(By.CSS_SELECTOR, "div.SiEggd a")
                    channel_name = ch_elem.text.strip()
                    channel_url = ch_elem.get_attribute("href")
                    subtitles.append({"name": channel_name, "url": channel_url})
                except:
                    pass

                results.append({
                    "header": "YouTube",
                    "title": title,
                    "titleUrl": title_url,
                    "subtitles": subtitles,
                    "time": time_iso,
                    "products": ["YouTube"],
                    "activityControls": ["YouTube watch history"]
                })

                # æ¯æ–°å¢ä¸€ç­†å°±å³æ™‚å¯«å…¥ json æª”æ¡ˆ
                with open(output_file, "w", encoding="utf-8") as f:
                    text = json.dumps(results, ensure_ascii=False, indent=2)
                    text = text.replace('},\n  {', '},{')
                    # è™•ç†åªæœ‰ä¸€å€‹å…ƒç´ çš„é™£åˆ—ï¼ˆsubtitles/products/activityControlsç­‰ï¼‰å£“æˆä¸€è¡Œï¼Œé™£åˆ—å¾Œé¢å¯æ¥é€—è™Ÿæˆ–å³å¤§æ‹¬è™Ÿ
                    text = re.sub(r'\[\n\s+({.*?})\n\s+\](,?)', r'[\1]\2', text)
                    text = re.sub(r'\[\n\s+(".*?")\n\s+\](,?)', r'[\1]\2', text)
                    f.write(text)

                new_found += 1
                print(f"[âœ“] æ–°å¢ï¼š{title} @ {time_iso}")

            except Exception as e:
                print(f"[ERR] æ´»å‹•è™•ç†å¤±æ•—ï¼š{e}")
                continue

        if new_found == 0:
            empty_rounds += 1
            print(f"[INFO] ç„¡æ–°å¢ï¼ˆ{empty_rounds}/{EMPTY_ROUND_THRESHOLD}ï¼‰")
            if empty_rounds >= EMPTY_ROUND_THRESHOLD:
                print("[STOP] ç„¡æ–°æ´»å‹•ï¼Œè‡ªå‹•çµæŸ")
                break
        else:
            empty_rounds = 0

        rounds += 1

    print(f"\nâœ… å…±å„²å­˜ {len(results)} ç­†æ´»å‹•è‡³ {output_file}")
    driver.quit()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--start-date', type=str, help='æŒ‡å®š max= åƒæ•¸ (æ ¼å¼: YYYY/MM/DD)', default=None)
    parser.add_argument('--end-date', type=str, help='çµæŸæ¢ä»¶ï¼Œé‡åˆ°å°æ–¼é€™å¤©çš„æ´»å‹•å°±åœæ­¢ (æ ¼å¼: YYYY/MM/DD)', default=None)
    parser.add_argument('--output', type=str, help='è¼¸å‡ºæª”æ¡ˆåç¨±', default='youtube_watch_history_stream.json')
    args = parser.parse_args()
    main(args.start_date, args.end_date, args.output)
